<!DOCTYPE html>
<html><head><meta charset="utf-8"></meta><title>Annonated Algorithm Visualization</title><link rel="stylesheet" href="pylit.css?v=1"></link><link rel="stylesheet" href="solarized.css"></link><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous"></link><script src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);" defer="True"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/lib/codemirror.min.css"></link><script src="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/lib/codemirror.min.js"></script><script src="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/mode/python/python.min.js"></script></head><body><div class="section" id="section-0"><div class="docs doc-strings"><p><p><a href="index.html"><b>HOME<br></b></a></p></p><a href="https://github.com/opendilab/PPOxFamily" target="_blank"><img alt="GitHub" style="max-width:100%;" src="https://img.shields.io/github/stars/opendilab/PPOxFamily?style=social"></img></a>  <a href="https://space.bilibili.com/1112854351?spm_id_from=333.337.0.0" target="_blank"><img alt="bilibili" style="max-width:100%;" src="https://img.shields.io/badge/bilibili-video%20course-blue"></img></a>  <a href="https://twitter.com/OpenDILab" rel="nofollow" target="_blank"><img alt="twitter" style="max-width:100%;" src="https://img.shields.io/twitter/follow/opendilab?style=social"></img></a><br><a href="https://github.com/opendilab/PPOxFamily/tree/main/chapter1_overview/a2c_zh.py" target="_blank">View code on GitHub</a><br><br>Advantage Actor-Critic (A2C) 算法的 PyTorch 版实现。<br><br>REINFORCE 方法通常对梯度估计有较高的方差，而 Actor-Critic 方法只能得到有偏的梯度估计。<br>为了结合这两种方法，A2C 使用基线函数进行归一化。通过从总回报中减去基线函数，减少了梯度估计的方差。<br>在实践中，基线函数通常被设置为价值函数。<br>最终的目标函数形式化定义为:<br>$$- \frac 1 N \sum_{n=1}^{N} log(\pi(a^n|s^n)) A^{\pi}(s^n, a^n)$$<br>同样，通过这种方式，可以保证估计是无偏的。<br>关于基线函数为什么可以减少梯度估计方差的补充材料请参考：<a href="https://github.com/opendilab/PPOxFamily/blob/main/chapter1_overview/chapter1_supp_a2c.pdf">Related Link</a><br><br>本文档主要包括:<br>- A2C error 的实现。<br>- 主函数（测试函数）</div></div><div class="section" id="section-1"><div class="docs doc-strings"><p>    <b>概述</b><br>        Advantage Actor-Critic (A2C) 算法的 PyTorch 版实现。 <a href="https://arxiv.org/pdf/1602.01783.pdf">Related Link</a></p></div><div class="code"><pre><code id="code_1" name="py_code">from collections import namedtuple
import torch
import torch.nn.functional as F

a2c_data = namedtuple('a2c_data', ['logit', 'action', 'value', 'adv', 'return_', 'weight'])
a2c_loss = namedtuple('a2c_loss', ['policy_loss', 'value_loss', 'entropy_loss'])


def a2c_error(data: namedtuple) -> namedtuple:</code></pre></div></div><div class="section" id="section-3"><div class="docs doc-strings"><p>    对数据 data 进行解包:  $$<\pi(a|s), a, V(s), A^{\pi}(s, a), G_t, w>$$</p></div><div class="code"><pre><code id="code_3" name="py_code">    logit, action, value, adv, return_, weight = data</code></pre></div></div><div class="section" id="section-4"><div class="docs doc-strings"><p>    准备默认的权重（weight）。</p></div><div class="code"><pre><code id="code_4" name="py_code">    if weight is None:
        weight = torch.ones_like(value)</code></pre></div></div><div class="section" id="section-5"><div class="docs doc-strings"><p>    根据 logit 构建策略分布，然后得到对应动作的概率的对数值。</p></div><div class="code"><pre><code id="code_5" name="py_code">    dist = torch.distributions.categorical.Categorical(logits=logit)
    logp = dist.log_prob(action)</code></pre></div></div><div class="section" id="section-6"><div class="docs doc-strings"><p>    策略的损失函数: $$- \frac 1 N \sum_{n=1}^{N} log(\pi(a^n|s^n)) A^{\pi}(s^n, a^n)$$</p></div><div class="code"><pre><code id="code_6" name="py_code">    policy_loss = -(logp * adv * weight).mean()</code></pre></div></div><div class="section" id="section-7"><div class="docs doc-strings"><p>    值函数的损失函数: $$\frac 1 N \sum_{n=1}^{N} (G_t^n - V(s^n))^2$$</p></div><div class="code"><pre><code id="code_7" name="py_code">    value_loss = (F.mse_loss(return_, value, reduction='none') * weight).mean()</code></pre></div></div><div class="section" id="section-8"><div class="docs doc-strings"><p>    熵 bonus：$$\frac 1 N \sum_{n=1}^{N} \sum_{a^n}\pi(a^n|s^n) log(\pi(a^n|s^n))$$<br>    注意：最终的损失函数是 <span style="color:#00cbf694;font-family:Monaco,IBMPlexMono;">policy_loss + value_weight * value_loss - entropy_weight * entropy_loss</span> .</p></div><div class="code"><pre><code id="code_8" name="py_code">    entropy_loss = (dist.entropy() * weight).mean()</code></pre></div></div><div class="section" id="section-9"><div class="docs doc-strings"><p>    Return the concrete loss items.<br>    返回最终的各项损失函数：包含策略损失，值损失和熵损失。</p></div><div class="code"><pre><code id="code_9" name="py_code">    return a2c_loss(policy_loss, value_loss, entropy_loss)

</code></pre></div></div><div class="section" id="section-10"><div class="docs doc-strings"><p>    <b>概述</b><br>        A2C 算法的测试函数，包括前向和反向传播测试</p></div><div class="code"><pre><code id="code_10" name="py_code">def test_a2c():</code></pre></div></div><div class="section" id="section-12"><div class="docs doc-strings"><p>    设置相关参数：batch size=4, action=32</p></div><div class="code"><pre><code id="code_12" name="py_code">    B, N = 4, 32</code></pre></div></div><div class="section" id="section-13"><div class="docs doc-strings"><p>    从随机分布中生成测试数据： logit, action, value, adv, return_.</p></div><div class="code"><pre><code id="code_13" name="py_code">    logit = torch.randn(B, N).requires_grad_(True)
    action = torch.randint(0, N, size=(B, ))
    value = torch.randn(B).requires_grad_(True)
    adv = torch.rand(B)
    return_ = torch.randn(B) * 2
    data = a2c_data(logit, action, value, adv, return_, None)</code></pre></div></div><div class="section" id="section-14"><div class="docs doc-strings"><p>    计算 A2C error</p></div><div class="code"><pre><code id="code_14" name="py_code">    loss = a2c_error(data)</code></pre></div></div><div class="section" id="section-15"><div class="docs doc-strings"><p>    测试 loss 是否是可微分的，是否能正确产生梯度</p></div><div class="code"><pre><code id="code_15" name="py_code">    assert logit.grad is None
    assert value.grad is None
    total_loss = sum(loss)
    total_loss.backward()
    assert isinstance(logit.grad, torch.Tensor)
    assert isinstance(value.grad, torch.Tensor)

</code></pre></div></div><div class="section" id="section-15"><div class="docs doc-strings"><p><i>如果读者关于本文档有任何问题和建议，可以在 GitHub 提 issue 或是直接发邮件给我们 (opendilab@pjlab.org.cn) 。</i></p></div></div></body><script type="text/javascript">
window.onload = function(){
    var codeElement = document.getElementsByName('py_code');
    var lineCount = 1;
    for (var i = 0; i < codeElement.length; i++) {
        var code = codeElement[i].innerText;
        if (code.length <= 1) {
            continue;
        }

        codeElement[i].innerHTML = "";

        var codeMirror = CodeMirror(
          codeElement[i],
          {
            value: code,
            mode: "python",
            theme: "solarized dark",
            lineNumbers: true,
            firstLineNumber: lineCount,
            readOnly: false,
            lineWrapping: true,
          }
        );
        var noNewLineCode = code.replace(/[\r\n]/g, "");
        lineCount += code.length - noNewLineCode.length + 1;
    }
};
</script></html>