<!DOCTYPE html>
<html><head><meta charset="utf-8"></meta><title>Annonated Algorithm Visualization</title><link rel="stylesheet" href="pylit.css?v=1"></link><link rel="stylesheet" href="solarized.css"></link><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css" integrity="sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/" crossorigin="anonymous"></link><script src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js" integrity="sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);" defer="True"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/lib/codemirror.min.css"></link><script src="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/lib/codemirror.min.js"></script><script src="https://cdn.jsdelivr.net/npm/codemirror@5.61.0/mode/python/python.min.js"></script></head><body><div class="section" id="section-0"><div class="docs doc-strings"><p><p><a href="index.html"><b>HOME<br></b></a></p></p><a href="https://github.com/opendilab/PPOxFamily" target="_blank"><img alt="GitHub" style="max-width:100%;" src="https://img.shields.io/github/stars/opendilab/PPOxFamily?style=social"></img></a>  <a href="https://space.bilibili.com/1112854351?spm_id_from=333.337.0.0" target="_blank"><img alt="bilibili" style="max-width:100%;" src="https://img.shields.io/badge/bilibili-video%20course-blue"></img></a>  <a href="https://twitter.com/OpenDILab" rel="nofollow" target="_blank"><img alt="twitter" style="max-width:100%;" src="https://img.shields.io/twitter/follow/opendilab?style=social"></img></a><br><a href="https://github.com/opendilab/PPOxFamily/tree/main/chapter7_tricks/value_clip.py" target="_blank">View code on GitHub</a><br><br>PPO Value Clip.<br><br>The Value-Clip Proximal Policy Optimization (PPO) technique is employed to place constraints on updates to the value function,<br>averting rapid fluctuations in the estimated value of a given state.<br>This method is devised to enhance the stability and reliability of the learning process during the training phase.<br>For additional details, please refer to the source paper: Implementation Matters in Deep RL: A Case Study on PPO and TRPO. <a href="https://arxiv.org/abs/2005.12729">Related Link</a>.</div></div><div class="section" id="section-1"><div class="docs doc-strings"><p>    <b>Overview</b><br>        Implementation of Value Clip method used in PPO. The core idea is to prevent the value function from updating too rapidly for a certain state.<br>        This is achieved by clipping the new value within a certain range of the old value.<br>    Arguments:<br>        - value_old (:obj:`torch.FloatTensor`): The old value, calculated using the old policy.<br>        - value_new (:obj:`torch.FloatTensor`): The new value, calculated using the new policy.<br>        - return_ (:obj:`torch.FloatTensor`): The expected return value (target value).<br>        - clip_ratio (:obj:`float`): The clipping range for the new value, expressed as a ratio of the old value. Default is 0.2.<br>    Returns:<br>        - value_loss (:obj:`torch.FloatTensor`): The calculated value loss, represents the difference between the new and old value function.<br><br>    <b>Algorithm</b><br>        The algorithm calculates the clipped value function and then calculates two types of value losses: one between the return and the new value function,<br>        and the other between the return and the clipped value function. The final value loss is the average of the maximum of these two types of value losses.</p></div><div class="code"><pre><code id="code_1" name="py_code">import torch


def ppo_value_clip(value_old: torch.FloatTensor, value_new: torch.FloatTensor, return_: torch.FloatTensor,
                   clip_ratio: float = 0.2) -> torch.FloatTensor:</code></pre></div></div><div class="section" id="section-3"><div class="docs doc-strings"><p>    Calculate the clipped value function, which is the old value plus the difference between the new and old value, clamped within the clip ratio.<br>    $$V_{clip} = V_{old} + clip(V_{new} - V_{old}, -clip\_ratio, clip\_ratio)$$</p></div><div class="code"><pre><code id="code_3" name="py_code">    value_clip = value_old + (value_new - value_old).clamp(-clip_ratio, clip_ratio)</code></pre></div></div><div class="section" id="section-4"><div class="docs doc-strings"><p>    Calculate the first type of value loss: the squared difference between the return and the new value function.<br>    $$V_1 = (return - V_{new})^2$$</p></div><div class="code"><pre><code id="code_4" name="py_code">    v1 = (return_ - value_new).pow(2)</code></pre></div></div><div class="section" id="section-5"><div class="docs doc-strings"><p>    Calculate the second type of value loss: the squared difference between the return and the clipped value function.<br>    $$V_2 = (return - V_{clip})^2$$</p></div><div class="code"><pre><code id="code_5" name="py_code">    v2 = (return_ - value_clip).pow(2)</code></pre></div></div><div class="section" id="section-6"><div class="docs doc-strings"><p>    Calculate the final value loss as the average of the maximum of the two types of value losses.<br>    $$loss = 0.5 * weight * max(V_1, V_2)$$</p></div><div class="code"><pre><code id="code_6" name="py_code">    value_loss = 0.5 * (torch.max(v1, v2)).mean()
    return value_loss

</code></pre></div></div><div class="section" id="section-7"><div class="docs doc-strings"><p>    <b>Overview</b><br>        Test function for ppo_value_clip function. The test case generates random data and uses it to calculate the value loss.<br>        Then it checks whether the shape of the returned value loss is a scalar, as expected.</p></div><div class="code"><pre><code id="code_7" name="py_code">def test_ppo_value_clip() -> None:</code></pre></div></div><div class="section" id="section-9"><div class="docs doc-strings"><p>    Generate random data for testing. The batch size is 6.</p></div><div class="code"><pre><code id="code_9" name="py_code">    B = 6
    value_old = torch.randn(B)
    value_new = torch.randn(B)
    return_ = torch.randn(B)</code></pre></div></div><div class="section" id="section-10"><div class="docs doc-strings"><p>    Calculate the value loss using the ppo_value_clip function.</p></div><div class="code"><pre><code id="code_10" name="py_code">    value_loss = ppo_value_clip(value_old, value_new, return_)</code></pre></div></div><div class="section" id="section-11"><div class="docs doc-strings"><p>    Assert that the returned value loss is a scalar (i.e., its shape is an empty tuple).</p></div><div class="code"><pre><code id="code_11" name="py_code">    assert value_loss.shape == torch.Size([])

</code></pre></div></div><div class="section" id="section-11"><div class="docs doc-strings"><p><i>If you have any questions or advices about this documation, you can raise issues in GitHub (https://github.com/opendilab/PPOxFamily) or email us (opendilab@pjlab.org.cn).</i></p></div></div></body><script type="text/javascript">
window.onload = function(){
    var codeElement = document.getElementsByName('py_code');
    var lineCount = 1;
    for (var i = 0; i < codeElement.length; i++) {
        var code = codeElement[i].innerText;
        if (code.length <= 1) {
            continue;
        }

        codeElement[i].innerHTML = "";

        var codeMirror = CodeMirror(
          codeElement[i],
          {
            value: code,
            mode: "python",
            theme: "solarized dark",
            lineNumbers: true,
            firstLineNumber: lineCount,
            readOnly: false,
            lineWrapping: true,
          }
        );
        var noNewLineCode = code.replace(/[\r\n]/g, "");
        lineCount += code.length - noNewLineCode.length + 1;
    }
};
</script></html>